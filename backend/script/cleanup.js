const mongoose = require('mongoose');
const fs = require('fs');
const path = require('path');
const Book = require('../models/book.model'); // Mod√®le des livres
const logger = require('../utils/logger');   // Winston pour les logs
require('dotenv').config();                  // Charger les variables d'environnement

// Connexion √† MongoDB
mongoose.connect(process.env.MONGO_URI, { useNewUrlParser: true, useUnifiedTopology: true })
  .then(() => {
    logger.info('‚úÖ Connexion √† MongoDB r√©ussie pour le script de nettoyage.');
    cleanupImages(); // Lancer le nettoyage
  })
  .catch(err => {
    logger.error('‚ùå Connexion √† MongoDB √©chou√©e :', err);
    process.exit(1);
  });

// Nettoyer les fichiers orphelins
async function cleanupImages() {
  try {
    const imagesDir = path.join(__dirname, '..', 'images'); // Dossier des images
    const files = fs.readdirSync(imagesDir); // Lire tous les fichiers du dossier images
    logger.info(`üìÇ Nombre de fichiers trouv√©s dans le dossier images : ${files.length}`);

    // R√©cup√©rer toutes les URLs d'images dans la base de donn√©es
    const books = await Book.find({}, 'imageUrl'); // On ne r√©cup√®re que les URLs des images
    const imageUrls = books.map(book => book.imageUrl);

    // V√©rifier chaque fichier du dossier
    let orphans = 0;
    files.forEach(file => {
      const filePath = `${process.env.BASE_URL || 'http://localhost:4000'}/images/${file}`;
      if (!imageUrls.includes(filePath)) {
        // Supprimer les fichiers non r√©f√©renc√©s dans la base de donn√©es
        fs.unlinkSync(path.join(imagesDir, file));
        logger.info(`üóëÔ∏è Fichier orphelin supprim√© : ${file}`);
        orphans++;
      }
    });

    logger.info(`‚úÖ Nettoyage termin√© : ${orphans} fichier(s) orphelin(s) supprim√©(s).`);
    process.exit(0); // Terminer le script
  } catch (err) {
    logger.error('‚ùå Erreur lors du nettoyage des fichiers orphelins :', err);
    process.exit(1);
  }
}
